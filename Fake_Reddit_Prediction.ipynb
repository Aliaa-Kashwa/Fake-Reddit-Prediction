{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RipVl2OQsChu"
      },
      "source": [
        "#**General Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iFlP2_IsK7M"
      },
      "source": [
        "üåà What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?\n",
        "\n",
        "1) \n",
        "\n",
        "Character N-Grams it is split each words based on character but word N-Grams it is split whole text based on words.\n",
        "\n",
        "Character N-grams split highlights some common properties that a word n-gram split does not.\n",
        "\n",
        "Character N-grams split allows to identify interesting similarities across languages.\n",
        "\n",
        "Character N-grams make languages more comparable revealing more repeated objects.\n",
        "\n",
        "2)\n",
        "\n",
        "Word n-gram tends to suffer more from OOV (Out-Of-Vocabulary) issue because of the new words that presented in the testing dataset and not appear in training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhthO9X_sMI6"
      },
      "source": [
        "üåà **What is the difference between stop word removal and stemming? Are these techniques language-dependent?**\n",
        "\n",
        "1)Stop word removal and stemming are commonly used method in indexing.\n",
        "\n",
        "* **Stop word removal** Some common words that are present in text but do not contribute in the meaning of a sentence. Such words are not at all important for the purpose of information retrieval or natural language processing. \n",
        "\n",
        "      For example: The most common stopwords are ‚Äòthe‚Äô and ‚Äòa‚Äô.\n",
        "\n",
        "* **Stemming** is a technique used to extract the base form of the words by removing affixes from them. It is just like cutting down the branches of a tree to its stems. \n",
        "      For example: the stem of the words eating, eats, eaten is eat.\n",
        "\n",
        "2) Yes, these techniques are language-dependent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aoo2p_osLha"
      },
      "source": [
        "üåà **Is tokenization techniques language dependent? Why?**\n",
        "\n",
        "Tokenization is breaking the raw text into small chunks and helps in interpreting the meaning of the text by analyzing the sequence of the words so it is language dependent.\n",
        "\n",
        "Because it needs to know meaning of each word to split it depend on language.\n",
        "           \n",
        "    For example: wasn't>> wasnt>>was n't>>wasn t >> these all possible of tokenization but some of these doesn't have meaning in the language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kuyN5WJsMWy"
      },
      "source": [
        "üåà **What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?**\n",
        "\n",
        "1) *TfidfVectorizer and CountVectorizer both are methods for converting text data into vectors as model can process only numerical data.*\n",
        "\n",
        "* **CountVectorizer**: Counts the frequency of all words in our corpus, sorts them and grabs the most recurring features (using max_features hyperparameter). But these results are mostly biased and our model might loose out on some of the important less frequent features. These are all boolean values. \n",
        "\n",
        "      For example: SEO People used to take advantage of this.\n",
        "\n",
        "* **TFIDFVectorizer**: TFIDF is a statistical measure said to have fixed the issues with CountVectorizer in some way. It consists of 2 parts, TF (Term Frequency) multiplied with IDF (Inverse Document Frequency). The main intuition being some words that appear frequently in 1 document and less frequently in other documents could be considered as providing extra insight for that 1 document and could help our model learn from this additional piece of information. In short, common words are penalized. These are relative frequencies identified as floating point numbers.\n",
        "\n",
        "---\n",
        "\n",
        "* In **CountVectorizer** we only count the number of times a word appears in the document which results in biasing in favour of most frequent words. this ends up in ignoring rare words which could have helped is in processing our data more efficiently.\n",
        "\n",
        "* In **TfidfVectorizer** we consider overall document weightage of a word. It helps us in dealing with most frequent words. Using it we can penalize them. TfidfVectorizer weights the word counts by a measure of how often they appear in the documents.\n",
        "\n",
        "**Summary**: The main difference between the 2 implementations is that TfidfVectorizer performs both term frequency and inverse document frequency for you, while using TfidfTransformer will require you to use the CountVectorizer class from Scikit-Learn to perform Term Frequency.\n",
        "\n",
        "---\n",
        "2)\n",
        "\n",
        "* It isn't feasible to use all possible n-grams.\n",
        "\n",
        "- N-gram range sets if features to be used to characterize texts will be:Unigrams or words (n-gram size = 1)Bigrams or terms compounded by two words (n-gram size = 2)Trigrams or terms compounded by up to three words (n-gram size = 3).\n",
        "\n",
        "- I should select between them depend on problem like :Sentiment Analysis, setting n-gram ranges that use bigrams or trigrams can dramatically improve the accuracy of classification,as they can capture more complex expressions formed by the composition of morethan one word. The rationale is that in Sentiment Analysis the outcome dependsnot only on the frequency of words but also on how they are combined:good has a different meaning alone than when preceded by a not as in not good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGBooHpxqnBk"
      },
      "source": [
        "#**Problem Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARcMJKuYq3OU"
      },
      "source": [
        "‚úîÔ∏è Problem Formulation:\n",
        "\n",
        " * This is a binary text classification task. Containing a tabular dataset called (\"Reddit Fake Post Detection (by Looking Only at the Title)\") and the excepected goal from it to classify the output of a specific title whether it is fake or not based on some text preprocessing on our data.\n",
        "\n",
        " * It has 2 features as input (the title as 'text' column & id column) and 1 feature as output (label column), we are going to predict the probability (0-1, float) that the title will be fake news or not. So we can ML model that can better solve this problem.\n",
        "\n",
        " * The data mining function that we need in this problems is binary text classification and predictions models for classifying our data and predict the appropriate label.\n",
        "\n",
        " * The challenges are that the dataset has not any missing values & quite balanced, but has some duplicated data points we should remove. And we should apply some preprocessing techniques on dataset like cleaning text and feature extraction and tuned the appropriate model for this problem.\n",
        "\n",
        "  * The impact of the product on real life help Reducing the spread of fake and false news by designing a model capable of differentiating between true and fake news with an acceptable accuracy, thus building an environment that is not supportive of misinformation and building trust with the general public.\n",
        "\n",
        "  * The life cycle of data mining model to be able to predict the probability of output whether it is fake or not that:\n",
        "\n",
        "        Problem understanding\n",
        "\n",
        "        Data collection.\n",
        "\n",
        "        Data preparation.\n",
        "\n",
        "        Modeling. \n",
        "\n",
        "        Evaluation.\n",
        "\n",
        "* What is an ideal solution?\n",
        "\n",
        "   The ideal solution is to make the appropriate preprocessing on the text column for properly predicting the probability of right label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLlVT4s7rSd-"
      },
      "source": [
        "What is the experimental protocol used and how was it carried out? What preprocessing steps are used?\n",
        "\n",
        "  * The experimental protocol used is (Validation set) that is a set of data, separate from the training set, that is used to validate our model performance during training. This validation process gives information that helps us tune the model's hyperparameters and configurations accordingly.\n",
        "\n",
        "               I splitted the whole data to train & validation with 20 % percentage for the validation and used it in Grid Search.\n",
        "\n",
        "\n",
        "   * I also used (The Cross-validation) because it is usually the preferred method as it gives the model the opportunity to train on multiple train-test splits. This gives a better indication of how well the model will perform on unseen data.\n",
        "\n",
        " * The general procedure is as follows:\n",
        "            Shuffle the dataset randomly.\n",
        "            Split the dataset into k groups\n",
        "            For each unique group:\n",
        "\n",
        "            Take the group as a hold out or test data set\n",
        "            Take the remaining groups as a training data set\n",
        "            Fit a model on the training set and evaluate it on the test set\n",
        "            Retain the evaluation score and discard the model\n",
        "\n",
        "  * Summarize the skill of the model using the sample of model evaluation scores\n",
        "\n",
        "* Preprocessing steps that I need:\n",
        "\n",
        "      1) Removing duplicated data.\n",
        "\n",
        "      2) Handling text column through applying some preprocessing steps on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgX7zTcFfy8o"
      },
      "source": [
        "#**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ojo5ilIie_6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import holoviews as hv\n",
        "import nltk \n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NMh10trigO5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSYddjXEKP6f"
      },
      "source": [
        "#**Import data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyxvVnzxigRn"
      },
      "outputs": [],
      "source": [
        "# Read train data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Reddit Fake Post Detection/xy_train.csv', sep=\",\", na_values=[\"\"])\n",
        "# Read test data\n",
        "df2= pd.read_csv('/content/drive/MyDrive/Reddit Fake Post Detection/x_test.csv', sep=\",\", na_values=[\"\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7-iHY2JKY8r"
      },
      "source": [
        "#**Data Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7bOoy2ZNigUI",
        "outputId": "add0bd0a-4308-420c-9bb9-c6862b44dc01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4  Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5debf52-5929-4392-bafc-022c354fc659\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5debf52-5929-4392-bafc-022c354fc659')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5debf52-5929-4392-bafc-022c354fc659 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5debf52-5929-4392-bafc-022c354fc659');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Drop id column from train data\n",
        "df.drop('id',axis=1,inplace=True)\n",
        "#Display the first 5 rows of train data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "E49-4_lniDWO",
        "outputId": "f3debacb-c2ba-4e80-e1ed-1f553c1eef83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Seeing another person whoÈà•Ê™ö also in need, you should just naturally be like, Èà•Ê•≠ want to help that person.Èà•?\\t0.84\\t1\\t0\\t0\\nNeoMegaRyuMKII\\tdenmark just trolled trump with a bus watch what happens when it moves\\t1489962542.0\\tarchive.is\\tTrue\\t60cu90\\thttps://external-preview.redd.it/s8HQxoWDwn2pt3eeBjIqetmGxvVMBBxaD93W08lGZrs.jpg?width=320&crop=smart&auto=webp&s=46f0ad18132126cab9823da4f3a6d6ec3a281bb2\\t\\t5.0\\t36\\tsavedyouaclick\\tDenmark Just Trolled Trump With A Bus. Watch What Happens When It Moves | Back wheels look like eyes that spin crazily as the bus moves (saved a click + short video that goes into slow motion (video mirror in comments since archive removed it))\\t0.92\\t0\\t2\\t5\\natbthefirst\\tyoung man theres no need to feel down\\t1429563057.0\\t\\tTrue\\tcqiw655\\thttp://i.imgur.com/rxTKm4U.jpg\\t338ute\\t\\t6\\tpsbattle_artwork\\tYoung man, there\\'s no need to feel down\\t\\t0\\t2\\t4\\nbeosronlto\\tmy onion ring chimp\\t1491483860.0\\timgur.com\\tTrue\\t63ss2x\\thttps://external-preview.redd.it/5muewXGrxJ6YS_iYpjqiBiXpIdxR7d7Woyyln7E4Xe4.jpg?width=320&crop=smart&auto=webp&s=68f0308f16bf0aa9dab6a28260dd06c85ed67450\\t\\t0.0\\t2\\tpareidolia\\tMy onion ring chimp\\t0.63\\t0\\t2\\t2\\nfood_SS\\tthis is what we eat in the images description\\t1443409099.0\\timgur.com\\tTrue\\t3mnjdi\\thttps://external-preview.redd.it/lLESgQetBjASylhfFUw6CKMfbKdR00WZA_LDVdXpOog.jpg?width=320&crop=smart&auto=webp&s=0cb7c577cf8f78d74b23db11f0069d3f32248d31\\t\\t20.0\\t20\\tsubredditsimulator\\tThis is what we eat in the images description)\\t0.84\\t0\\t2\\t3\\nCardboardSoyuz\\tarizona man purchases home and discovers an underground hatch in backyard\\t1505215025.0\\tweb.archive.org\\tTrue\\t6zmas6\\thttps://external-preview.redd.it/FBVXMNmhDNTqADXsiP9UE-NxQ7Caq5kTInsgl-BSvWI.jpg?width=320&crop=smart&auto=webp&s=cdf12b2b558aed4d0ad86199ea3d9592ff1f88c2\\t\\t7.0\\t613\\tsavedyouaclick\\tArizona Man Purchases Home And Discovers An Underground Hatch In Backyard | It leads to an old fall-out shelter in pretty good shape. It had a couple of cans of supplies in it, too. 17 clicks.\\t0.98\\t0\\t2\\t5\\nHarry_Butz\\tthe rpics awards spell out penis\\t1565605730.0\\ti.redd.it\\tTrue\\tcpajkp\\thttps://preview.redd.it/w948d5n4wzf31.jpg?width=320&crop=smart&auto=webp&s=a165988b2d70ef55257a8eeaeedf51b710f1a55b\\t\\t3.0\\t10\\tmildlyinteresting\\tThe /r/Pics awards spell out penis\\t0.71\\t1\\t0\\t0\\nbillarastg\\ttime traveller assassin attemps to take down obama before he becomes president circa\\t1551597882.0\\ti.redd.it\\tTrue\\tawrrxk\\thttps://preview.redd.it/behjedplvuj21.jpg?width=320&crop=smart&auto=webp&s=42ad1a826403a3575fbb94e823d47999b34cfbbd\\t\\t6.0\\t28\\tfakehistoryporn\\tTime traveller Assassin attemps to take down Obama before he becomes president. (circa 1952).\\t0.87\\t0\\t2\\t2\\nMissMaria86\\tew\\t1407262199.0\\t\\tTrue\\tcjhqf8a\\thttp://i.imgur.com/YBE2jms.jpg\\t2coipv\\t\\t95\\tpsbattle_artwork\\tEw.\\t\\t0\\t2\\t4\\nsnlisha\\tislamic state fighters reenter ancient palmyra in syria\\t1481392782.0\\tbbc.com\\tTrue\\t5hlch8\\thttps://external-preview.redd.it/rofxJBXObS76fw5nPTXg4tT9OXFHK-kvH33bZQyaO_8.jpg?width=320&crop=smart&auto=webp&s=02cc00050036279a3ae533ba8540830043fff74a\\t\\t0.0\\t5\\tneutralnews\\tIslamic State fighters \\'re-enter ancient Palmyra\\' in Syria\\t0.79\\t1\\t0\\t0\\nRaidyRafy\\ttop golf red line warning sign how many people have gotten hurt\\t1568605849.0\\ti.redd.it\\tTrue\\td4vcq7\\thttps://preview.redd.it/xtjcu5f0pvm31.jpg?width=320&crop=smart&auto=webp&s=9562ffe4127a0d6d34360e4df8a81e05de126519\\t\\t4.0\\t12\\tmildlyinteresting\\tTop Golf red line warning sign. How many people have gotten hurt?\\t0.83\\t1\\t0\\t0\\nBudrickBundy\\tthe nfls ratings slide was mainly fueled by white viewers and younger viewers\\t1516117668.0\\tawfulannouncing.com\\tTrue\\t7qt5fc\\thttps://external-preview.redd.it/vq1q3olqrN3tSCHnl2XJm349y4aGAnSEyepo6LkyFYQ.jpg?width=320&crop=smart&auto=webp&s=38bc55460c5785dbfb3dc2932c1e0321a1fe626c\\t\\t17.0\\t5\\tusanews\\tThe NFL\\'s 2017 ratings slide was mainly fueled by white viewers and younger viewers\\t0.69\\t1\\t0\\t0\\nbbizzess\\tmeryl streep marries\\t1475121888.0\\tarchive.is\\tTrue\\t550gen\\thttps://external-preview.redd.it/QaioECFejw0fZN8SE5WoeGkfu3rRHO3fbYKq_4Ae3b4.jpg?width=320&crop=smart&auto=webp&s=8a4d0ebe34e0e8f3b3b4f163a8369c92e1fb2c14\\t\\t1.0\\t34\\tsavedyouaclick\\tMeryl Streep Marries | Article says she\\'s marrying Robert Redford. She is not.\\t0.94\\t0\\t2\\t5\\nApiContraption\\tother discussions\\t1393550555.0\\t\\tTrue\\tcfqkht6\\thttp://i.imgur.com/XZObVs4%2ejpg\\t1z5152\\t\\t1\\tpsbattle_artwork\\tOther Discussions\\t\\t0\\t2\\t4\\nAskesl\\tsquash dingres\\t1447949876.0\\t\\tTrue\\tcx5t9jt\\thttp://i.imgur.com/4WrG3N6.jpg\\t3tfgjo\\t\\t242\\tpsbattle_artwork\\tSquash d\\'Ingres\\t\\t0\\t2\\t4\\nGrahamSaysNO\\tthis cactus man\\t1409262115.0\\timgur.com\\tTrue\\t2ev0r6\\thttps://external-preview.redd.it/tod214DPHe8fopeWeF_9MJUVbRXDR2tr78uzMrZSa2E.jpg?width=320&crop=smart&auto=webp&s=e6486a1ed49915388d5b756ae11b4f5e88bc64c4\\t\\t6.0\\t54\\tpareidolia\\tThis cactus man.\\t0.91\\t0\\t2\\t2\\nIShitPoopsALot\\troommates stab each other over debate between iphone and samsung\\t1429265409.0\\tktul.com\\tTrue\\t32wpnv\\thttps://external-preview.redd.it/TypZIEwJmWacgv45TjxxCrHXytjUCkLmhYjZUZatYmU.jpg?width=320&crop=smart&auto=webp&s=4cef96c45cc0f50e2d64f829daa184449136b89e\\t\\t183.0\\t1175\\tnottheonion\\tRoommates stab each other over debate between iPhone and Samsung.\\t0.93\\t1\\t0\\t0\\nslithek\\tgot rid of the ant\\t1365912044.0\\t\\tTrue\\tc9es9hx\\thttp://i.imgur.com/HOCK1nE.jpg\\t1cairr\\t\\t99\\tpsbattle_artwork\\tGot rid of the ant...\\t\\t0\\t2\\t4\\nJJ935\\ttitanic\\t1557350663.0\\t\\tTrue\\temv7vw0\\thttps://i.imgur.com/WIYL8aT.jpg\\tbm9yhe\\t\\t3\\tpsbattle_artwork\\tTitanic\\t\\t0\\t2\\t4\\nThigira\\tdeclaration of independence philadelphia\\t1553375330.0\\ti.redd.it\\tTrue\\tb4o9wf\\thttps://preview.redd.it/9v1epg3voxn21.jpg?width=320&crop=smart&auto=webp&s=eece10bb46d039890257c34ace5de65900928c13\\t\\t3.0\\t81\\tfakehistoryporn\\tDeclaration of Independence. Philadelphia, 1776. Colorized\\t0.91\\t0\\t2\\t2\\nBobblee20\\tthis cloud formation against a sunrise looks like a fire tornado\\t1551025203.0\\ti.redd.it\\tTrue\\tau9fsm\\thttps://preview.redd.it/f6kfxc7qkji21.jpg?width=320&crop=smart&auto=webp&s=bd863086c477286b4c2cdb4ca3fa0b547494c118\\t\\t1.0\\t48\\tmildlyinteresting\\tThis cloud formation against a sunrise looks like a fire tornado\\t0.93\\t1\\t0\\t0\\nChispy\\tobligatory faceswap\\t1472415912.0\\t\\tTrue\\td70cdmk\\thttp://i.imgur.com/KbRXBLs.jpg\\t4zzhjk\\t\\t60\\tpsbattle_artwork\\tobligatory faceswap\\t\\t0\\t2\\t4\\nVt412\\texcited dog\\t1367321385.0\\ti.imgur.com\\tTrue\\t1dekok\\thttps://external-preview.redd.it/ESPM-tTuK3werLgfWG_wBsw_trUSDNU4bI5s2jVRAgQ.png?width=108&crop=smart&auto=webp&s=6bdf4d9c8ec6b3100f803c1cf0848f49a5aee344\\t\\t1.0\\t1\\tphotoshopbattles\\tExcited dog\\t0.53\\t1\\t0\\t0\\nratchetraccoon\\tphotograph of first interracial family in pennsylvania after interracial marriage is legalized circa\\t1524449884.0\\ti.redd.it\\tTrue\\t8e84ku\\thttps://preview.redd.it/mydnsd5oikt01.jpg?width=320&crop=smart&auto=webp&s=dbcf91c9c5aacb9f49c2e2cdf5f9f8dcca3b7d8d\\t\\t4.0\\t103\\tfakehistoryporn\\tColorized photograph of first interracial family in Pennsylvania after interracial marriage is legalized, circa 1780\\t0.97\\t0\\t2\\t2\\nMrtenpence\\tmy local bus has usb chargers in every seat\\t1537876887.0\\timgur.com\\tTrue\\t9iri2s\\thttps://external-preview.redd.it/8OSU-4_TeshCI8i0-Qokoj4-GnuIeAsl1uS7Y5-yAko.jpg?width=320&crop=smart&auto=webp&s=ccbf8c98e0c00fb8f459a421a4a3d5f29dc05a18\\t\\t32.0\\t261\\tmildlyinteresting\\tMy local bus has USB chargers in every seat\\t0.92\\t1\\t0\\t0\\nLucastWaddle\\tthe fact that people keep buying this stuff at the ace harware i work at in texas\\t1561857484.0\\ti.redd.it\\tTrue\\tc7790i\\thttps://preview.redd.it/uj09xvsnae731.jpg?width=320&crop=smart&auto=webp&s=9b174799db2c906c646b9a8999e76d4dedc97a09\\t\\t4.0\\t7\\tmildlyinteresting\\tThe fact that people keep buying this stuff at the Ace Harware I work at in Texas.\\t0.82\\t1\\t0\\t0\\nOriginalstix\\thuge tennis racket or mini federer\\t1451981052.0\\t\\tTrue\\tcymkq8f\\thttp://i.imgur.com/kWNXbnZ.jpg\\t3zfune\\t\\t1\\tpsbattle_artwork\\thuge tennis racket or mini federer?\\t\\t0\\t2\\t4\\nmangobutter6179\\tthese cigs in mexico have a photo of a dead body on it also picked it up at a pharmacy who was selling it secretly lol\\t1568731999.0\\ti.redd.it\\tTrue\\td5i3v2\\thttps://preview.redd.it/jy5rsoi446n31.jpg?width=320&crop=smart&auto=webp&s=30c4d1ab9ff12513839b3492606c02d4dad3fedf\\t\\t7.0\\t8\\tmildlyinteresting\\tThese cigs in Mexico have a photo of a dead body on it, also picked it up at a pharmacy who was selling it secretly lol\\t0.75\\t1\\t0\\t0\\n9elefanttwoothpaste7\\tfat man bomb dropped on nagasaki\\t1501655233.0\\ti.imgur.com\\tTrue\\t6r2cz7\\thttps://external-preview.redd.it/Pk13Js7E_zB5abguKu7q7vJkzSol8soRomMY2bQsOcU.jpg?width=320&crop=smart&auto=webp&s=1846378b13372ae5a072f7c7494bc15b9243288d\\t\\t0.0\\t4\\tmisleadingthumbnails\\tFat Man bomb dropped on Nagasaki, 1945 (colorized)\\t0.57\\t0\\t2\\t2\\nViperdream\\tdeath is close\\t1364940402.0\\t\\tTrue\\tc978mws\\thttp://i.imgur.com/vW3hyor.jpg\\t1biplz\\t\\t1\\tpsbattle_artwork\\tDeath is close...\\t\\t0\\t2\\t4\\nMohhh777\\tbritish soldiers during a last stand in the battle of el alamein\\t1520350464.0\\ti.redd.it\\tTrue\\t82fx19\\thttps://preview.redd.it/q0pxntkzw5k01.jpg?width=320&crop=smart&auto=webp&s=f5e3a60c7d11e99167a41d139f7aafadfd572eab\\t\\t1.0\\t6\\tfakehistoryporn\\tBritish soldiers during a last stand in the battle of el alamein (1942,colorized)\\t0.87\\t0\\t2\\t2\\nWaffleSmoof\\ta year old doingthis\\t1466958003.0\\ti.imgur.com\\tTrue\\t4pyfx6\\thttps://external-preview.redd.it/E5eDuxcbUIShmnalJeNwxFdygee8fD8wnPkva04grGk.jpg?width=320&crop=smart&auto=webp&s=a55dceaa0d3d8be7b860c503b3ebbe881b2c4de9\\t\\t8.0\\t5\\tphotoshopbattles\\tPsBattle: A 4-year old doing...this\\t0.86\\t1\\t0\\t0\\nj_Wlms\\tboov\\t1480133670.0\\t\\tTrue\\tdafx4a6\\thttp://i64.tinypic.com/2iqi36.jpg\\t5etd1l\\t\\t3\\tpsbattle_artwork\\tboov\\t\\t0\\t2\\t4\\nLordMetrognome\\tthese puppies\\t1560574409.0\\ti.redd.it\\tTrue\\tc0tmcc\\thttps://preview.redd.it/cfv54djfbg431.jpg?width=320&crop=smart&auto=webp&s=4e3def0be13bf80708e56b7d1d787da9dc992953\\t\\t6.0\\t35\\tphotoshopbattles\\tPsBattle: These 3 puppies\\t0.85\\t1\\t0\\t0\\nswigsweg8897\\twe raced another plane on my flight back from europe the other day\\t1536676609.0\\timgur.com\\tTrue\\t9ey3ng\\thttps://external-preview.redd.it/gG22KFjIVjNARSyZPlTpL34Fs_O-IJ-Po07K_4JCkBA.jpg?width=320&crop=smart&auto=webp&s=21d02ead80ce93e5a3066d4285bd580a3d98d700\\t\\t5.0\\t13\\tmildlyinteresting\\tWe raced another plane on my flight back from Europe the other day\\t0.85\\t1\\t0\\t0\\nBlackjack115\\ttexas woman uses her coupon clipping skills to help hurricane survivors\\t1505681867.0\\tabcnews.go.com\\tTrue\\t70q7na\\thttps://external-preview.redd.it/X34E8Gwjznfyqi_wuBHow-e6zi3caqVn8IQ8zWx82CU.jpg?width=320&crop=smart&auto=webp&s=ba32edcc58727c1de53e72a37fd51aeae0ef9887\\t\\t615.0\\t29035\\tupliftingnews\\tTexas woman uses her coupon clipping skills to help hurricane survivors\\t0.87\\t1\\t0\\t0\\nApiContraption\\tcutouts\\t1412348760.0\\t\\tTrue\\tckzeba8\\thttp://i.imgur.com/uSH1Cwe%2ejpg\\t2i6ymd\\t\\t2\\tpsbattle_artwork\\tcutouts\\t\\t0\\t2\\t4\\njargos\\tidk might be nsfw\\t1373170717.0\\t\\tTrue\\tcaxeexm\\thttp://i.imgur.com/B9oD0ac.jpg\\t1hs7jh\\t\\t15\\tpsbattle_artwork\\tIDK, might be NSFW\\t\\t0\\t2\\t4\\nene_due_rabe\\tdeep inside shes no different\\t1524409377.0\\t\\tTrue\\tdxs4e1p\\thttps://i.imgur.com/pQnFFRS.jpg\\t8e2py4\\t\\t3\\tpsbattle_artwork\\tDeep inside she\\'s no different\\t\\t0\\t2\\t4\\nRizilus\\tbig head\\t1524535418.0\\t\\tTrue\\tdxv3mcd\\thttps://i.imgur.com/Kfo4au9.jpg\\t8ee4tt\\t\\t2\\tpsbattle_artwork\\tBig Head\\t\\t0\\t2\\t4\\nchibucks\\teveryone looks so yummy\\t1445894162.0\\t\\tTrue\\tcwdtq0c\\thttp://i.imgur.com/FA7Tni2.jpg\\t3q9z4g\\t\\t15\\tpsbattle_artwork\\teveryone looks so yummy\\t\\t0\\t2\\t4\\n\\tthis guy at the adult vr festival in tokyo this weekend\\t1465819487.0\\ti.kinja-img.com\\tTrue\\t4nvas9\\thttps://external-preview.redd.it/1XEjZYusUBXwJndja1lHPuCW4NFz7j80OCfBd7XiTAY.jpg?width=320&crop=smart&auto=webp&s=e80adfcb9b709fb98556ce09261ee53de045800b\\t\\t349.0\\t9551\\tphotoshopbattles\\tPsBattle: This guy at the Adult VR Festival in Tokyo this weekend\\t0.89\\t1\\t0\\t0\\nDizzyEllie\\tobligitory\\t1476226457.0\\t\\tTrue\\td8o0chd\\thttp://i.imgur.com/z0PnFE0.jpg\\t56z02p\\t\\t2\\tpsbattle_artwork\\tObligitory.\\t\\t0\\t2\\t4\\nall-top-today_SS\\telephant seal pup says hello to a post from a few floors above\\t1559336297.0\\ti.redd.it\\tTrue\\tbvctt3\\thttps://preview.redd.it/g0c53pmrlf131.jpg?width=320&crop=smart&auto=webp&s=1de627c4a23e85b629d107d7e1ebc7b06b1d39ee\\t\\t18.0\\t101\\tsubredditsimulator\\tElephant seal pup says hello to a post from a few floors above\\t0.96\\t0\\t2\\t3\\nshinji3\\twhat elon doesnt want you to see\\t1518287809.0\\t\\tTrue\\tdu1mjqa\\thttps://i.imgur.com/xRbpvxW.jpg\\t7wl1vo\\t\\t71\\tpsbattle_artwork\\tWhat Elon doesn\\'t want you to see\\t\\t0\\t2\\t4\\nTheCreativeNick\\tblue turtle with a dirty shell\\t1563833741.0\\ti.redd.it\\tTrue\\tcgjwhn\\thttps://preview.redd.it/9qdsw151jxb31.jpg?width=320&crop=smart&auto=webp&s=c4c5c2ade1810433a3e371e72a5a2d848464f7ae\\t\\t408.0\\t24511\\tphotoshopbattles\\tPsBattle: Blue turtle with a dirty shell\\t0.96\\t1\\t0\\t0\\ncauseofb\\tjapanese depiction of an american warship\\t1476659895.0\\ti.imgur.com\\tTrue\\t57u8n9\\thttps://external-preview.redd.it/DaZZGGLadbj-qSzlJ96STTAfhrlUqz6MbTn5AK3wsGw.jpg?width=320&crop=smart&auto=webp&s=d188c0f83b3d2e8072ad9c7bf585cbb682876baa\\t\\t67.0\\t1105\\tpropagandaposters\\tJapanese depiction of an American warship, 1854\\t0.97\\t0\\t1\\t5\\n\\tlittle girl in a white dress looking out a window\\t1436536622.0\\timgur.com\\tTrue\\t3csr8n\\thttps://external-preview.redd.it/PwEtMoKSLV6YSSn3kpk-UyRocldOPcAEAGqQO9XoO2k.jpg?width=320&crop=smart&auto=webp&s=87f9ff5781ff0b8153faba6f7387211fa953b0bf\\t\\t6.0\\t100\\tmisleadingthumbnails\\tLittle girl in a white dress looking out a window.\\t0.86\\t0\\t2\\t2\\nDrXtreme28\\tkeep your head above\\t1399860594.0\\t\\tTrue\\tchfm9uw\\thttp://i.imgur.com/J4Qwfi4.jpg\\t25b9e2\\t\\t31\\tpsbattle_artwork\\tKeep your head above\\t\\t0\\t2\\t4\\nIf_You_Only_Knew\\toh north koreas invading well let me just go and get my fucking clown shoes\\t1363142770.0\\t\\tTrue\\tc8umnyd\\thttp://i.imgur.com/HMPT52I.jpg\\t1a6upj\\t\\t27\\tpsbattle_artwork\\tOh, North Korea\\'s invading? Well, let me just go and get my fucking clown shoes.\\t\\t0\\t2\\t4\\nGetMotivated_SS\\tarticle one of the rest of us are wasting our lives\\t1448287091.0\\tbrainpickings.org\\tTrue\\t3txxj1\\thttps://external-preview.redd.it/r2qrGFfHPGuFWTCeXdjcly6Ew7UlC5yR2urSZuHoW74.jpg?width=320&crop=smart&auto=webp&s=381feada4235ba6e4686f149b41f78007bd7a02e\\t\\t20.0\\t9\\tsubredditsimulator\\t[Article] One of the rest of us are wasting our lives\\t0.91\\t0\\t2\\t3\\nartunitinc\\tthis one\\t1468845225.0\\t\\tTrue\\td5gpz50\\thttp://i.imgur.com/JPJBsz0.jpg\\t4td1bc\\t\\t33\\tpsbattle_artwork\\tthis one?\\t\\t0\\t2\\t4\\nkoi666\\tbored christmas cat\\t1482768667.0\\ti.reddituploads.com\\tTrue\\t5kecl5\\thttps://external-preview.redd.it/_oeEZ21UIWYl9qySzhuhOBihXfL8pHd-q4ThRcoTuTI.jpg?width=320&crop=smart&auto=webp&s=3f81abc8b3013db4e2121338709f2242c20abdcb\\t\\t1.0\\t5\\tphotoshopbattles\\tPsBattle: Bored Christmas cat\\t0.86\\t1\\t0\\t0\\nkluste\\twhere is the fucking backup\\t1476130417.0\\t\\tTrue\\td8mbzus\\thttp://i.imgur.com/4BkCTlU.jpg\\t56tith\\t\\t2\\tpsbattle_artwork\\tWhere is the fucking backup!?!?!\\t\\t0\\t2\\t4\\nal0c-ac0c\\tbeen staring at this one eared cyclops mouse on my train ride through scotland\\t1568824896.0\\timgur.com\\tTrue\\td60g9w\\thttps://external-preview.redd.it/Y3Wr32rXNPudybPwgaFelgcf2rkiyrGSb9jmV8n0nCA.jpg?width=320&crop=smart&auto=webp&s=f99b7f97505aadb40d816857877158668a3b85b5\\t\\t1.0\\t6\\tpareidolia\\tBeen staring at this one eared Cyclops mouse on my train ride through Scotland.\\t0.88\\t0\\t2\\t2\\nall-top-today_SS\\tmy first gaming pc just arrived in brazil i am sick of politicians giving the same thing as donald trumps star on the head\\t1485817095.0\\ti.imgur.com\\tTrue\\t5r48ow\\thttps://external-preview.redd.it/ESPM-tTuK3werLgfWG_wBsw_trUSDNU4bI5s2jVRAgQ.png?width=108&crop=smart&auto=webp&s=6bdf4d9c8ec6b3100f803c1cf0848f49a5aee344\\t\\t20.0\\t31\\tsubredditsimulator\\tMy first gaming pc just arrived in Brazil, I am sick of politicians giving the same thing as Donald Trump\\'s star on the head\\t0.88\\t0\\t2\\t3\\nalsobrante\\tmit engineer browsing incognito mode on early computer\\t1538338579.0\\ti.imgur.com\\tTrue\\t9k9lgj\\thttps://external-preview.redd.it/O20cyX0xei4nvxlKlFepHyl3JcqI3Hm-pN7E2415_U8.png?width=320&crop=smart&auto=webp&s=d16e7d0d23250c36644e90b66e2e5c9fe559dd6d\\t\\t4.0\\t173\\tfakehistoryporn\\tMIT engineer browsing incognito mode on early computer (1983)\\t1.0\\t0\\t2\\t2\\nalloutnow\\ttrump blocks release of democratic memo on russia probe\\t1518225144.0\\treuters.com\\tTrue\\t7wi82s\\thttps://external-preview.redd.it/U5Y07YbILjhjvhQiiaawsr2jdIwnO2Fxd1C_d24xYw4.jpg?width=320&crop=smart&auto=webp&s=9edaf07bda93aa9a9d24ee418fa53470fbd32cc2\\t\\t1.0\\t23\\tusanews\\tTrump blocks release of Democratic memo on Russia probe | Reuters\\t0.83\\t1\\t0\\t0\\nFoxprowl\\tthe city of los angeles at night seen from space\\t1502384619.0\\ti.redd.it\\tTrue\\t6sup0y\\thttps://preview.redd.it/w3y6f99jixez.jpg?width=320&crop=smart&auto=webp&s=69fa24f2862da454d01a71b6639a27ad491fcbc6\\t\\t0.0\\t10\\tmisleadingthumbnails\\tThe city of Los Angeles at night seen from space\\t0.71\\t0\\t2\\t2\\nblackbanhmi\\ta coffee shop in vietnam where you can soak your feet in anklelevel water with swimming fish\\t1537851239.0\\ti.redd.it\\tTrue\\t9ip9m3\\thttps://preview.redd.it/y1grvezrfbo11.jpg?width=320&crop=smart&auto=webp&s=85a8240a4042389f1d53d9046f983993ddabebd8\\t\\t24.0\\t87\\tmildlyinteresting\\tA coffee shop in Vietnam, where you can soak your feet in ankle-level water with swimming fish\\t0.91\\t1\\t0\\t0\\nSimmo5150\\tthe strangers at the mountains of madness\\t1522416520.0\\ti.redd.it\\tTrue\\t88abtq\\thttps://preview.redd.it/f5vy9qi7kwo01.jpg?width=320&crop=smart&auto=webp&s=b819fa1c7096cf275cf65a26dca2e33b64e429aa\\t\\t2.0\\t49\\tfakealbumcovers\\tThe Strangers - At The Mountains Of Madness\\t0.98\\t0\\t2\\t1\\n\\tirafsky district tender compassions x\\t1422020514.0\\ti.imgur.com\\tTrue\\t2tehcz\\thttps://external-preview.redd.it/FZyyQnZrEkI997h31MdaUxrkQf4hlDirrd9uLXIckOc.png?width=320&crop=smart&auto=webp&s=c71ff486b5d749cd93313a3cc14d86cbeae3e2e2\\t\\t1.0\\t7\\tfakealbumcovers\\tIrafsky District - Tender Compassions {1040x1040}\\t1.0\\t0\\t2\\t1\\nroset_ta\\tthis world leader missing from his chair\\t1566852595.0\\ti.redd.it\\tTrue\\tcvtwtq\\thttps://preview.redd.it/poaq69oe7ti31.jpg?width=320&crop=smart&auto=webp&s=ad1bb72a6d731a440bcd33256c53b1504c1540a0\\t\\t14.0\\t30\\tphotoshopbattles\\tPsBattle: This world leader missing from his chair.\\t0.81\\t1\\t0\\t0\\nOxTox\\tmy cat dreaming about his future as a basketballer\\t1374694335.0\\ti.imgur.com\\tTrue\\t1iz5p0\\thttps://external-preview.redd.it/Kt6FWE0rz41rDzlHbrtZjl1nZl4SBnTOBquEJ7DHbyQ.jpg?width=320&crop=smart&auto=webp&s=d69173783daa7e0dba2c9d2b3abfdadc650d5d69\\t\\t6.0\\t3\\tphotoshopbattles\\tMy cat dreaming about his future as a basketballer.\\t0.72\\t1\\t0\\t0\\nChesleaFc\\ther period gone wild\\t1420259337.0\\ti.imgur.com\\tTrue\\t2r69ma\\thttps://external-preview.redd.it/psWSM7m7r_Zuw7dMUg_BBi4BLMor_CRXtEZkrcFyLww.jpg?width=320&crop=smart&auto=webp&s=fb315ebd5bdae391657e48b8fad4bdebe63b8af3\\t\\t5.0\\t63\\tmisleadingthumbnails\\tHer period gone wild\\t0.68\\t0\\t2\\t2\\nMyEmptyBagOfChips\\tthese snails crowded on a tree\\t1557935912.0\\ti.imgur.com\\tTrue\\tbozp05\\thttps://external-preview.redd.it/6O_jT6jvg3Hw1_yIeiJuo1c621jDd2cJYCQcb2JNkmo.jpg?width=320&crop=smart&auto=webp&s=c8acfe313a1737754086f16f07a30124da959b6a\\t\\t5.0\\t21\\tphotoshopbattles\\tPsBattle: These snails crowded on a tree\\t0.8\\t1\\t0\\t0\\nfried_egg_on_toast\\ti was driving and saw this house that had a sperm kite flying outside\\t1564947960.0\\ti.redd.it\\tTrue\\tcm0o0a\\thttps://preview.redd.it/krgpibi8khe31.jpg?width=320&crop=smart&auto=webp&s=18fb1c436e2a825af71a2380646a29297d51affc\\t\\t14.0\\t8\\tmildlyinteresting\\tI was driving and saw this house that had a sperm kite flying outside\\t0.79\\t1\\t0\\t0\\nramong941\\tdont skip leg day\\t1447339550.0\\ti.imgur.com\\tTrue\\t3sjdx0\\thttps://external-preview.redd.it/Y-UA9ez9xIbJ7DW4ee44psznfbgrZYDlp9MCd_aNS6M.jpg?width=320&crop=smart&auto=webp&s=e2fbd201c861263735f76e0ad196907448736152\\t\\t3.0\\t366\\tconfusing_perspective\\tDon\\'t skip leg day\\t0.95\\t0\\t2\\t2\\nApiContraption\\tcutouts\\t1407988458.0\\t\\tTrue\\tcjpqh64\\thttp://i.imgur.com/aQdK3Cd%2ejpg\\t2di8gm\\t\\t1\\tpsbattle_artwork\\tcutouts\\t\\t0\\t2\\t4\\nJohnJTaylor\\tstate has st elk sighting in more than centuries\\t1477570409.0\\tmsn.com\\tTrue\\t59nmlp\\thttps://external-preview.redd.it/GK9zzWdnSgLiJfA0UoZ-6RI4PgInibREyfSNBj_xZHo.jpg?width=320&crop=smart&auto=webp&s=31042c360e26d9aea8294e62ff4ea3636b5ff12f\\t\\t3.0\\t18\\tupliftingnews\\tState has 1st elk sighting in more than 2 centuries\\t0.89\\t1\\t0\\t0\\nWOSBen\\twish you were here\\t1468486664.0\\t\\tTrue\\td5bqhmr\\thttp://i.imgur.com/6dHjTDU.jpg\\t4srok6\\t\\t550\\tpsbattle_artwork\\t\"Wish you were here\"\"\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#The first title in train data\n",
        "df['text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEfR0CvhA1z6",
        "outputId": "f8922ed8-f71d-4eae-82e4-087f18a0dd43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#shape of train data\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCz-lbDABdDV",
        "outputId": "9eadd016-f39a-4249-e36a-4084acda54aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     59645\n",
              "label        3\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#number of unique values in each column in train data\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdCQ1XkDHHoH",
        "outputId": "d3286e64-8105-4ebf-9cc9-af41ffa3c7ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    32172\n",
              "1    27596\n",
              "2      232\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#count of unique values in label column\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nZg6WfIBx8I"
      },
      "source": [
        "**Observation:** Label 2 has no meaning in our problem here (outliers) so we should remove data points that contain this label later because we have label 1 indiates fake news and label 0 indicates not fake news."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW7GxVa5T2jC"
      },
      "outputs": [],
      "source": [
        "#drop data points that contain label 2\n",
        "df.drop(df.loc[df[\"label\"]==2].index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ3gCt7Zj0QC",
        "outputId": "a3733e2c-4f28-4573-8cf6-189853543413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.538281\n",
              "1    0.461719\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Distribution of labels\n",
        "df[\"label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class balance analysis\n",
        "df[['label']].hist(bins = 3)\n",
        "plt.bar(np.arange(len([0,1])), df.groupby(['label']).size().values, 0.9,  color=\"blue\")\n",
        "plt.xticks(np.arange(len([0,1])), [0,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1WGLlswXY9IC",
        "outputId": "ada597be-18c6-485d-9c34-c8db48f218d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** From the plot we see that we have balanced data."
      ],
      "metadata": {
        "id": "78pjayX3ZYjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  the number of characters present in each title by labels\n",
        "df['text'].str.len().hist(by=df['label']);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "NIfHg23fZqqe",
        "outputId": "a418f4f3-5ab2-42f7-a1b6-b83edefa627c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word level analysis of title\n",
        "df['text'].str.split().apply(lambda x:[len(i) for i in x]).map(lambda x: np.mean(x)).hist(by=df['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "LxPIPtjhZ1F4",
        "outputId": "71dc3dc2-6744-4c6d-c49a-ca26363ddf2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f1def5427d0>,\n",
              "       <matplotlib.axes._subplots.AxesSubplot object at 0x7f1def54b250>],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of train data after removing data points that contain label 2\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LclyHxxbVmeM",
        "outputId": "05a1a760-64cf-46ce-e732-11e8a0a64606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59768, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SuYLZCsCOxL",
        "outputId": "598897ff-a951-430e-ff12-3376afffab8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "345"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#check for duplicated data\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72DSa_YVj7jO"
      },
      "source": [
        "**Observation:** We have 345 duplicated data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38st23q7CXRQ",
        "outputId": "e23a7398-381c-4870-d905-0162b744e159"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "#drop duplicated data\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v_PFplpDLXm"
      },
      "source": [
        "**Observation:** Now we have no duplicated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWvLlTf1DIts",
        "outputId": "4a199840-df65-427f-a11e-db9da9b62ca7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59423, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "#shape of train data after we remove duplicated data\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XxaR11nDnOM",
        "outputId": "9e7b5428-ba2b-4f3d-9704-3b140a94d1c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "#chack for missing values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZInOqVdDt4R"
      },
      "source": [
        "**Observation:** We have no missing values in our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx7BGt6XKgzh"
      },
      "source": [
        "#**Working on data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll focus on the titles amd the labels, which have value 1 for fake news and 0 for true ones. The titles are mostly written in proper English with some outliers from Chinese language using punctuation and have image and websites links and don't include emojis. However, as with any real life text data there will be slang, grammatical mistakes, misspellings etc. Also, in some places we find html tags like <br />. Nonetheless, compared to data from Facebook or Twitter this is mostly harmless and probably won't pose too many issues for us. We will deal with all of that in the next step."
      ],
      "metadata": {
        "id": "e7OpOB6al_s-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **I will apply two different cleaning functions on data and see the results of each of them**"
      ],
      "metadata": {
        "id": "TyqWG8cFcE6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**First cleaning Function**"
      ],
      "metadata": {
        "id": "QHvFrT0xb_jX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5a-tjmsigWp",
        "outputId": "15db22cc-aff2-41b8-eabe-e2d7a7b9b4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Building function for Cleaning the dataset\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    clean_text = \" \".join(words_filtered)\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The (clean_text) function takes a string input and applies a bunch of manipulations to it (described in the code)."
      ],
      "metadata": {
        "id": "ZF08T4sLpPqK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U0j9VTKtigZG",
        "outputId": "81bc4cdf-713f-46f2-a062-9358c044f9df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'python best program languag'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "#try the first cleaning function on an example\n",
        "clean_text(\"Python is ; \\ the best Programming language.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Second cleaning Function**"
      ],
      "metadata": {
        "id": "zwJntJEucXfB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLD9D3IQ9uTp",
        "outputId": "67971ca4-b8f7-40ca-a933-ea47069f02e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Building function for Cleaning the dataset\n",
        "def different_clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords and punctuation\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    clean_text = \" \".join(words_tokens_lower)\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The (different_clean_text) function takes a string input and applies a bunch of manipulations to it (described in the code)."
      ],
      "metadata": {
        "id": "TN71E6eip2j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#try the first cleaning function on an example\n",
        "different_clean_text(\"Python is ; \\ the best Programming language.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zKGpVVmLcjrJ",
        "outputId": "c7abfc9f-2aad-4475-fecf-ccfc9014c7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'python is the best programming language'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Applying the first clean function on train & test data**"
      ],
      "metadata": {
        "id": "x2IVbwa4ZkYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX4W5qjSigbe",
        "outputId": "ef4f0bff-bfa8-45a0-f43c-751fc61b0101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21.5 s, sys: 3.27 ms, total: 21.5 s\n",
            "Wall time: 21.6 s\n"
          ]
        }
      ],
      "source": [
        "#applying the first cleaning function on train data \n",
        "#and put the output of this cleaning process in new column(\"clean_text\")\n",
        "%%time\n",
        "# Clean text in train data (24 s)\n",
        "df[\"clean_text\"] = df.loc[df[\"text\"].str.len() > 0, \"text\"]\n",
        "df[\"clean_text\"] = df[\"clean_text\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oix-38W4Sw6U",
        "outputId": "96a404ed-0db6-428c-eb90-11a787387222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.6 s, sys: 23 ms, total: 11.6 s\n",
            "Wall time: 11.7 s\n"
          ]
        }
      ],
      "source": [
        "#applying the first cleaning function on test data \n",
        "#and put the output of this cleaning process in new column(\"clean_text\")\n",
        "%%time\n",
        "# Clean text in test data (13 s)\n",
        "df2[\"clean_text\"] = df2.loc[df2[\"text\"].str.len() > 0, \"text\"]\n",
        "df2[\"clean_text\"] = df2[\"clean_text\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Applying the second clean function on train & test data**"
      ],
      "metadata": {
        "id": "t9RfnC-cZv5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVeDno9b-BKF",
        "outputId": "d8d91ce0-1fea-4ece-f039-dc404a9d71a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.09 s, sys: 43.7 ms, total: 9.13 s\n",
            "Wall time: 9.48 s\n"
          ]
        }
      ],
      "source": [
        "#applying the second cleaning function on train data \n",
        "#and put the output of this cleaning process in new column(\"different_clean_text\")\n",
        "%%time\n",
        "# Clean text in train data (24 s)\n",
        "df[\"different_clean_text\"] = df.loc[df[\"text\"].str.len() > 0, \"text\"]\n",
        "df[\"different_clean_text\"] = df[\"different_clean_text\"].map(\n",
        "    lambda x: different_clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF-23ZJ5-BXc",
        "outputId": "b1501fbb-8a39-4f1e-d4e5-03270a6bc11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.46 s, sys: 36.4 ms, total: 6.5 s\n",
            "Wall time: 6.51 s\n"
          ]
        }
      ],
      "source": [
        "#applying the second cleaning function on test data \n",
        "#and put the output of this cleaning process in new column(\"different_clean_text\")\n",
        "%%time\n",
        "# Clean text in test data (13 s)\n",
        "df2[\"different_clean_text\"] = df2.loc[df2[\"text\"].str.len() > 0, \"text\"]\n",
        "df2[\"different_clean_text\"] = df2[\"different_clean_text\"].map(\n",
        "    lambda x: different_clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These steps conclude the cleaning and pre processing. In result, we get this:"
      ],
      "metadata": {
        "id": "4-BC-HUc8Syc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Display the head of train & test data after applying the cleaning functions.**"
      ],
      "metadata": {
        "id": "0LO2ITy_dCQz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "rbKLEXWEigdz",
        "outputId": "d6be8614-3442-4c9b-9ef0-9694417682b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4  Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "   label  \\\n",
              "0      0   \n",
              "1      0   \n",
              "2      0   \n",
              "3      0   \n",
              "4      0   \n",
              "\n",
              "                                                                                            clean_text  \\\n",
              "0  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...   \n",
              "1  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...   \n",
              "2  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...   \n",
              "3  happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...   \n",
              "4  obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...   \n",
              "\n",
              "                                                                                  different_clean_text  \n",
              "0  group of friends began to volunteer at homeless shelter after their neighbors protested seeing a...  \n",
              "1  british prime minister theresa may on nerve attack on former russian spy the government has conc...  \n",
              "2  in goodyear released kit that allows ps to be brought to heel https youtube com watch alxulk cg ...  \n",
              "3  happy birthday bob barker the price is right host on how he like to be remembered as the man who...  \n",
              "4  obama to nation innocent cops and unarmed young black men should not be dying before magic johns...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-876ef4f9-e951-4470-9a4d-b3e54f7f8937\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>different_clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "      <td>group of friends began to volunteer at homeless shelter after their neighbors protested seeing a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "      <td>british prime minister theresa may on nerve attack on former russian spy the government has conc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "      <td>in goodyear released kit that allows ps to be brought to heel https youtube com watch alxulk cg ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "      <td>happy birthday bob barker the price is right host on how he like to be remembered as the man who...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "      <td>obama to nation innocent cops and unarmed young black men should not be dying before magic johns...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-876ef4f9-e951-4470-9a4d-b3e54f7f8937')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-876ef4f9-e951-4470-9a4d-b3e54f7f8937 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-876ef4f9-e951-4470-9a4d-b3e54f7f8937');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "#display the five row fron train data after adding clean text column\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "REiSUeTiTJpg",
        "outputId": "763915bd-749a-4339-9fb6-14ec49066208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                                            text  \\\n",
              "0   0                                                      stargazer    \n",
              "1   1                                                            yeah   \n",
              "2   2      PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3   3  As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4   4                                    \"Believers\" - Hezbollah 2011   \n",
              "\n",
              "                                       clean_text  \\\n",
              "0                                         stargaz   \n",
              "1                                            yeah   \n",
              "2  pd phoenix car thief get instruct youtub video   \n",
              "3            trump accus iran one problem credibl   \n",
              "4                                believ hezbollah   \n",
              "\n",
              "                                           different_clean_text  \n",
              "0                                                     stargazer  \n",
              "1                                                          yeah  \n",
              "2     pd phoenix car thief gets instructions from youtube video  \n",
              "3  as trump accuses iran he has one problem his own credibility  \n",
              "4                                           believers hezbollah  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-112cfed8-cdec-45ad-bc96-f541c2d3eb96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>different_clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargaz</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>pd phoenix car thief get instruct youtub video</td>\n",
              "      <td>pd phoenix car thief gets instructions from youtube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>trump accus iran one problem credibl</td>\n",
              "      <td>as trump accuses iran he has one problem his own credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believ hezbollah</td>\n",
              "      <td>believers hezbollah</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-112cfed8-cdec-45ad-bc96-f541c2d3eb96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-112cfed8-cdec-45ad-bc96-f541c2d3eb96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-112cfed8-cdec-45ad-bc96-f541c2d3eb96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "#display the five row fron test data after adding clean text column\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjqh82u9j0Kp",
        "outputId": "bbb404c8-ece7-4742-e8ba-fc2ac88f95c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "one         3274\n",
              "like        3119\n",
              "new         2974\n",
              "look        2841\n",
              "color       2725\n",
              "man         2718\n",
              "get         2593\n",
              "trump       2552\n",
              "say         2322\n",
              "peopl       2311\n",
              "use         2302\n",
              "first       2232\n",
              "make        2222\n",
              "old         2216\n",
              "time        2018\n",
              "poster      1999\n",
              "found       1997\n",
              "day         1926\n",
              "war         1851\n",
              "post        1614\n",
              "world       1565\n",
              "work        1527\n",
              "show        1507\n",
              "us          1496\n",
              "american    1489\n",
              "take        1482\n",
              "life        1478\n",
              "psbattl     1469\n",
              "help        1439\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words\n",
        "word_freq = pd.Series(\" \".join(df[\"clean_text\"]).split()).value_counts()\n",
        "word_freq[1:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "MJVCn34_j0NW",
        "outputId": "b486ec5e-581e-4196-f9bc-116531cee40b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        index  freq\n",
              "0  valdiserri     1\n",
              "1        miku     1\n",
              "2      hatsun     1\n",
              "3       nfler     1\n",
              "4      hicock     1\n",
              "5      mccall     1\n",
              "6     angriff     1\n",
              "7     kutemey     1\n",
              "8       ollow     1\n",
              "9        wahr     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76406370-fac9-4213-bfd5-eacbe4ca8d00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>valdiserri</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>miku</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hatsun</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nfler</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hicock</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mccall</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>angriff</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>kutemey</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ollow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>wahr</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76406370-fac9-4213-bfd5-eacbe4ca8d00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76406370-fac9-4213-bfd5-eacbe4ca8d00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76406370-fac9-4213-bfd5-eacbe4ca8d00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# list most uncommon words\n",
        "word_freq[-10:].reset_index(name=\"freq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbRnWNuqJGc"
      },
      "source": [
        "#**Analyzer(Word)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP5rrkgjj0VI",
        "outputId": "9c75d8a4-9816-459f-e5cc-31b29a9a87fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.3, min_df=5, ngram_range=(1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "\"\"\"\n",
        "Compute unique word vector with frequencies\n",
        "exclude very uncommon (<5 obsv.) and common (>=30%) words\n",
        "use pairs of two words (ngram)\n",
        "\"\"\"\n",
        "vectorizer_word = TfidfVectorizer( analyzer=\"word\", max_df=0.3, min_df=5, ngram_range=(1, 2), norm=\"l2\")\n",
        "vectorizer_word.fit(df[\"clean_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFo50fyukAPx",
        "outputId": "728345d7-fb55-48ed-b653-95c5ad37299d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique word (ngram) vector extract:\n",
            "\n",
            " asphalt            950\n",
            "littl brother    10301\n",
            "german invad      6976\n",
            "allow see          385\n",
            "alien              350\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Vector representation of vocabulary\n",
        "word_vector = pd.Series(vectorizer_word.vocabulary_).sample(5, random_state=1)\n",
        "print(f\"Unique word (ngram) vector extract:\\n\\n {word_vector}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Zlo-61t4Je"
      },
      "source": [
        "#**Analyzer(Char)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Q1mzyEt4Jf",
        "outputId": "8e03d1a9-1189-4195-d3ed-274fc1d8a490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='char', max_df=0.3, min_df=5, ngram_range=(1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "\"\"\"\n",
        "Compute unique char vector with frequencies\n",
        "exclude very uncommon (<5 obsv.) and common (>=30%) char\n",
        "use pairs of two words (ngram)\n",
        "\"\"\"\n",
        "vectorizer_char = TfidfVectorizer( analyzer=\"char\", max_df=0.3, min_df=5, ngram_range=(1, 2), norm=\"l2\")\n",
        "vectorizer_char.fit(df[\"clean_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nVFUFWdt4Jg",
        "outputId": "fd6c7be7-ee56-465f-a42c-8b6905591b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique char (ngram) vector extract:\n",
            "\n",
            " y     618\n",
            "gm    174\n",
            "ge    166\n",
            "kw    286\n",
            "tr    500\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Vector representation of vocabulary\n",
        "char_vector = pd.Series(vectorizer_char.vocabulary_).sample(5, random_state=1)\n",
        "print(f\"Unique char (ngram) vector extract:\\n\\n {char_vector}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZk5jJ6SkGYK"
      },
      "source": [
        "#**Splitting Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN_i2CWQ4syd"
      },
      "outputs": [],
      "source": [
        "#split data to features(X) & Label(y)\n",
        "X = df['clean_text']\n",
        "X_2 = df['different_clean_text']\n",
        "Y = df['label'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-mARD7mJJkc",
        "outputId": "e45e346b-ccc6-4658-d391-58907efa2410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47538,)\n",
            "(11885,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 0.2, random_state = 2022, shuffle=True)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train (new training set), X\n",
        "split_index = [-1 if x in X_train.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtB_TY_5xukN"
      },
      "source": [
        "#**For Example: When applying word analyzer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT50XT5ZkAU2",
        "outputId": "90af6597-edb7-4199-8d52-5d73de2bdf96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47538, 21006)\n",
            "(59151, 21006)\n"
          ]
        }
      ],
      "source": [
        "# transform each sentence to numeric vector with tf-idf value as elements\n",
        "X_train_vec = vectorizer_word.transform(X_train)\n",
        "X_test_vec = vectorizer_word.transform(X_test)\n",
        "train_vec = vectorizer_word.transform(X)\n",
        "test_vec = vectorizer_word.transform(df2['clean_text'])\n",
        "test_vec_2 = vectorizer_word.transform(df2['different_clean_text'])\n",
        "\n",
        "print(X_train_vec.get_shape())\n",
        "print(test_vec.get_shape())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPHTjwYCkAXV",
        "outputId": "cb2bacaa-aa1c-4a69-ad65-73a46688af61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sentence:\n",
            "['chanc get hand bone muslim allegi lie']\n",
            "\n",
            "Vector representation of sentence:\n",
            "      allegi      bone    chanc  chanc get       get  get hand      hand  \\\n",
            "0  0.400142  0.333481  0.30195   0.435792  0.183692  0.425982  0.235193   \n",
            "\n",
            "        lie    muslim  \n",
            "0  0.299905  0.295173  \n"
          ]
        }
      ],
      "source": [
        "# Compare original comment text with its numeric vector representation\n",
        "print(f\"Original sentence:\\n{X_train[3:4].values}\\n\")\n",
        "# Feature Matrix\n",
        "features = pd.DataFrame(\n",
        "    X_train_vec[3:4].toarray(), columns=vectorizer_word.get_feature_names_out()\n",
        ")\n",
        "nonempty_feat = features.loc[:, (features != 0).any(axis=0)]\n",
        "print(f\"Vector representation of sentence:\\n {nonempty_feat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwne6Cymx1fp"
      },
      "source": [
        "#**For Example: When applying char analyzer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMEv4FtqxlbN",
        "outputId": "1fc5d96d-3c9b-4c1f-926b-ed22fb6f3f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47538, 673)\n",
            "(59151, 673)\n"
          ]
        }
      ],
      "source": [
        "# transform each sentence to numeric vector with tf-idf value as elements\n",
        "X_train_vec = vectorizer_char.transform(X_train)\n",
        "X_test_vec = vectorizer_char.transform(X_test)\n",
        "train_vec = vectorizer_char.transform(X)\n",
        "test_vec = vectorizer_char.transform(df2['clean_text'])\n",
        "test_vec_2 = vectorizer_char.transform(df2['different_clean_text'])\n",
        "\n",
        "\n",
        "print(X_train_vec.get_shape())\n",
        "print(test_vec.get_shape())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptnub8Y7xlpg",
        "outputId": "b3bd39e3-e8d6-4a31-a067-8b85902416aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sentence:\n",
            "['chanc get hand bone muslim allegi lie']\n",
            "\n",
            "Vector representation of sentence:\n",
            "          bo        c         eg        et        ge        gi        ha  \\\n",
            "0  0.237544  0.206579  0.294943  0.185989  0.223945  0.272964  0.416541   \n",
            "\n",
            "         ie        im        ll        m         mu        nc        sl  \\\n",
            "0  0.234799  0.237526  0.186083  0.198438  0.296463  0.237275  0.338145   \n",
            "\n",
            "         us  \n",
            "0  0.192518  \n"
          ]
        }
      ],
      "source": [
        "# Compare original comment text with its numeric vector representation\n",
        "print(f\"Original sentence:\\n{X_train[3:4].values}\\n\")\n",
        "# Feature Matrix\n",
        "features = pd.DataFrame(\n",
        "    X_train_vec[3:4].toarray(), columns=vectorizer_char.get_feature_names_out()\n",
        ")\n",
        "nonempty_feat = features.loc[:, (features != 0).any(axis=0)]\n",
        "print(f\"Vector representation of sentence:\\n {nonempty_feat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWIFGhQWXxNA"
      },
      "source": [
        "#**Model(1): LogReg + (analyzer='word')  with (Grid Search) using (Validation set)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZlBFzdVQgTr"
      },
      "source": [
        "*After we removed the words that are less important for analysis, hence that is making the model building less complex by reducing the input dimensions, we will choose the appropriate model for the task.*\n",
        "\n",
        "**Model is:** Logistic regression \n",
        "* As it is a simple yet very effective classification algorithm so it is commonly used for many binary classification tasks.\n",
        "\n",
        "* LogisticRegression 's important hyperparameters that we used here:\n",
        "\n",
        "      1)**C**, default=1.0, is a regularization parameter that controls the trade off between the achieving a low training error and a low testing error that is the ability to generalize your classifier to unseen data\n",
        "\n",
        "      2) **solver**{‚Äònewton-cg‚Äô, ‚Äòlbfgs‚Äô, ‚Äòliblinear‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô}, default=‚Äôlbfgs‚Äô. \n",
        "      Algorithm to use in the optimization problem. \n",
        "\n",
        "      3) **max_iterint**, default=100\n",
        "      Maximum number of iterations taken for the solvers to converge.\n",
        "\n",
        "\n",
        "\n",
        "**TfidfVectorizer:**\n",
        "\n",
        "* TF-IDF enables us to gives us a way to associate each word in a document with a number that represents how relevant each word is in that document. Then, documents with similar, relevant words will have similar vectors, which is what we are looking for in a machine learning algorithm.\n",
        "\n",
        "* It is better than Count Vectorizers because it not only focuses on the frequency of words present in the corpus but also provides the importance of the words.\n",
        "\n",
        "* It is better that TF. Word2Vec can be directly used to assign vector to a word but to get the vector representation of a document further processing is needed. Unlike TF-IDF Word2Vec takes into account placement of words in a document(to some extent).\n",
        "\n",
        "* **Hint: Output Term Frequency-Inverse Document Frequency matrix, specified as a sparse matrix or a cell array of sparse matrices.**\n",
        "\n",
        "* It has some important hyperparameters that we used in tuning that they are:\n",
        "\n",
        "      1) **max_df** When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). (remove more frequent words)\n",
        "\n",
        "      2) **min_df** When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature.(remove more rare words)\n",
        "\n",
        "      3) **ngram_range** tuple (min_n, max_n), default=(1, 1)\n",
        "      The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
        "\n",
        "      4) **analyzer** {‚Äòword‚Äô, ‚Äòchar‚Äô, ‚Äòchar_wb‚Äô}, default=‚Äôword‚Äô\n",
        "      Whether the feature should be made of word or character n-grams. \n",
        "\n",
        "\n",
        "**Pipeline:** we used a pipeline that provides a way to automate a machine learning workflow. It chained TfidfVectorizer & our model together."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here what did we use ‚Åâ**\n",
        "\n",
        "- word analyzer \n",
        "- ngram_range(1,2): means unigrams and bigrams.\n",
        "- max_df : range between (.1:1).\n",
        "- min_df : range between (5:15) with step 5.\n",
        " \n",
        " **We keep everything between max_df and min_df**\n",
        "- C : range between (.6:.9)\n",
        "- max_iter: 2 values(180,200) larger than the default value(100) to help the solver to converge.\n",
        "- random_state : (set to 42) to shuffle the data.\n",
        "\n",
        "- Grid Search using Validation set."
      ],
      "metadata": {
        "id": "cImsTaIZtqzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I suggest Logistic Regression model will work well with this problem with high accuracy.**"
      ],
      "metadata": {
        "id": "20XB8SxywWYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-Qo1FmkVdW",
        "outputId": "2f2d7593-1001-45b1-8ec6-4f34a5c789fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 144 candidates, totalling 144 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ..., -1,  0])),\n",
              "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('LogReg',\n",
              "                                        LogisticRegression(random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'LogReg__C': [0.6, 0.7, 0.8, 0.9],\n",
              "                         'LogReg__max_iter': [180, 200],\n",
              "                         'tfidf__analyzer': ['word'],\n",
              "                         'tfidf__max_df': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
              "                         'tfidf__min_df': array([ 5, 10]),\n",
              "                         'tfidf__ngram_range': [(1, 2)]},\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LogReg\", LogisticRegression(random_state=42))])\n",
        "\n",
        "# define parameter space to test # runtime 49min\n",
        "params = {\n",
        "     \"tfidf__analyzer\":['word'],\n",
        "     \"tfidf__ngram_range\": [(1, 2)],\n",
        "     \"tfidf__max_df\": np.arange(0.1, 1,.1),\n",
        "    \"tfidf__min_df\": np.arange(5,15,5),\n",
        "     \"LogReg__C\": [.6,.7,.8,0.9],  \n",
        "     \"LogReg__max_iter\":[180,200]    \n",
        "}\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"roc_auc\", cv= pds ,verbose=1)\n",
        "pipe_clf.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIavzDeUvOXf",
        "outputId": "4008c267-5066-41bb-ccad-a0ddc4e2313d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'LogReg__C': 0.9, 'LogReg__max_iter': 180, 'tfidf__analyzer': 'word', 'tfidf__max_df': 0.1, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "#display the best parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** the above cell returned the best hyperparametered with validation set using GridSearch .\n",
        "\n",
        "* max_df = 1.0, which means \"ignore terms that appear in more than 100% of the documents\". Thus, it did not ignore any terms.\n",
        "\n",
        "* min_df = 5 , which means \"ignore terms that appear in less than 5 documents\".\n",
        "\n",
        "* Smaller value of C specify stronger regularization. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CdO3-YyTwrf2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNSQgW9ukkf-",
        "outputId": "3174483f-550c-449c-f76d-5dfc04a1ef3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86     31955\n",
            "           1       0.83      0.83      0.83     27468\n",
            "\n",
            "    accuracy                           0.85     59423\n",
            "   macro avg       0.84      0.84      0.84     59423\n",
            "weighted avg       0.85      0.85      0.85     59423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, Y)\n",
        "pipe_pred = pipe.predict(X)\n",
        "report = sklearn.metrics.classification_report(Y, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** it achieved 85% on whole training data."
      ],
      "metadata": {
        "id": "voslT7360Y_L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qOGjBxM5-Pf"
      },
      "source": [
        "#**Model(2): LogReg + (analyzer='char')  with (Grid Search) using (Validation set)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here what did we use ‚Åâ**\n",
        "\n",
        "- char analyzer with the same hyperparameters as the previous trial.\n",
        "- Grid Search using Validation set."
      ],
      "metadata": {
        "id": "7S8O7Wzd1PQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I suggest Logistic Regression model will work worser than the previous trial as here it use char analyzer that care less about the meaning of context**"
      ],
      "metadata": {
        "id": "i_0aFk1v1j6h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCWrD2Th5-Pm",
        "outputId": "1709b95c-0840-4fd5-9a48-f829c3d78396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 144 candidates, totalling 144 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ..., -1,  0])),\n",
              "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('LogReg',\n",
              "                                        LogisticRegression(random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'LogReg__C': [0.6, 0.7, 0.8, 0.9],\n",
              "                         'LogReg__max_iter': [180, 200],\n",
              "                         'tfidf__analyzer': ['char'],\n",
              "                         'tfidf__max_df': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
              "                         'tfidf__min_df': array([ 5, 10]),\n",
              "                         'tfidf__ngram_range': [(1, 2)]},\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LogReg\", LogisticRegression(random_state=42))])\n",
        "\n",
        "# define parameter space to test # runtime 49min\n",
        "params = {\n",
        "     \"tfidf__analyzer\":['char'],\n",
        "     \"tfidf__ngram_range\": [(1, 2)],\n",
        "     \"tfidf__max_df\": np.arange(0.1, 1,.1),\n",
        "    \"tfidf__min_df\": np.arange(5,15,5),\n",
        "     \"LogReg__C\": [.6,.7,.8,0.9],  \n",
        "     \"LogReg__max_iter\":[180,200]     \n",
        "}\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"roc_auc\", cv= pds ,verbose=1)\n",
        "pipe_clf.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBwmb8HN5-Pu",
        "outputId": "71d2dd26-b763-4e60-e71d-88c9b69bd67e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'LogReg__C': 0.9, 'LogReg__max_iter': 180, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.7000000000000001, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "#display the best parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** the above cell returned the best hyperparametered with validation set using GridSearch .\n",
        "\n",
        "* max_df = .7, means \"ignore terms that appear in more than 70% of the documents\".\n",
        "\n",
        "* min_df = 5 , which means \"ignore terms that appear in less than 5 documents\".\n",
        "\n",
        "* Smaller value of C specify stronger regularization."
      ],
      "metadata": {
        "id": "j8KWcChj38uU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJdYHBNF5-P0",
        "outputId": "5446dbdd-d8fa-4287-c0a6-aec4cbcf6ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.73      0.71     31955\n",
            "           1       0.66      0.61      0.63     27468\n",
            "\n",
            "    accuracy                           0.67     59423\n",
            "   macro avg       0.67      0.67      0.67     59423\n",
            "weighted avg       0.67      0.67      0.67     59423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, Y)\n",
        "pipe_pred = pipe.predict(X)\n",
        "report = sklearn.metrics.classification_report(Y, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** it achieved 67% on whole training data.\n",
        "\n",
        " which indicated that word analyzer is better in this case."
      ],
      "metadata": {
        "id": "n1XlMzss4Rwz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN_O6d8q5-ZB"
      },
      "source": [
        "#**Model(3): LogReg + (analyzer='word')  with (Grid Search) using (Cross Validation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here what did we use ‚Åâ**\n",
        "\n",
        "- word analyzer with the same hyperparameters as the previous trial.\n",
        "- Grid Search using Cross Validation (cv=3)."
      ],
      "metadata": {
        "id": "VDLLYQTZ7Wof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I suggest Logistic Regression model will work as same as the first trial as it use word analyzer with same hyperparameters but the difference (using cv=3 instead of validation set) is small**"
      ],
      "metadata": {
        "id": "4zWtP-ui7YES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz-mYsVM5-ZF",
        "outputId": "f27ab323-155e-499b-e82a-c5940d10e55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10,\n",
              "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('LogReg',\n",
              "                                        LogisticRegression(random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'LogReg__C': [0.6, 0.7, 0.8, 0.9],\n",
              "                         'LogReg__max_iter': [180, 200],\n",
              "                         'tfidf__analyzer': ['word'],\n",
              "                         'tfidf__max_df': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
              "                         'tfidf__min_df': array([ 5, 10]),\n",
              "                         'tfidf__ngram_range': [(1, 2)]},\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LogReg\", LogisticRegression(random_state=42))])\n",
        "\n",
        "# define parameter space to test # runtime 49min\n",
        "params = {\n",
        "     \"tfidf__analyzer\":['word'],\n",
        "     \"tfidf__ngram_range\": [(1, 2)],\n",
        "     \"tfidf__max_df\": np.arange(0.1, 1,.1),\n",
        "    \"tfidf__min_df\": np.arange(5,15,5),\n",
        "     \"LogReg__C\": [.6,.7,.8,0.9],  \n",
        "     \"LogReg__max_iter\":[180,200]    \n",
        "}\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"roc_auc\", cv= 3 ,verbose=1)\n",
        "pipe_clf.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KaYEPsM5-ZJ",
        "outputId": "026222a7-43ac-4e0e-f7f1-a951da662e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'LogReg__C': 0.9, 'LogReg__max_iter': 180, 'tfidf__analyzer': 'word', 'tfidf__max_df': 0.1, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "#display the best parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** Greattt, it worked as we expected and chosed the same hyperparameters using the grid search."
      ],
      "metadata": {
        "id": "TCrP-Pjp8FY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aksYqtrt5-ZM",
        "outputId": "47e43774-62f7-43c2-c029-16ebd7e4bc91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86     31955\n",
            "           1       0.83      0.83      0.83     27468\n",
            "\n",
            "    accuracy                           0.85     59423\n",
            "   macro avg       0.84      0.84      0.84     59423\n",
            "weighted avg       0.85      0.85      0.85     59423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, Y)\n",
        "pipe_pred = pipe.predict(X)\n",
        "report = sklearn.metrics.classification_report(Y, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** it achieved 85% on whole training data."
      ],
      "metadata": {
        "id": "EWOovpiJ8ZKr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps3lB6Zy5-ii"
      },
      "source": [
        "#**Model(4): LogReg + (analyzer='char')  with (Grid Search) using (Cross Validation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here what did we use ‚Åâ**\n",
        "\n",
        "- char analyzer with the same hyperparameters as the previous trial.\n",
        "- Grid Search using Cross Validation (cv=3)."
      ],
      "metadata": {
        "id": "HNtfl9t0CBep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I suggest Logistic Regression model will work as same as the second trial as it use char analyzer with same hyperparameters but the difference (using cv=3 instead of validation set) is small**"
      ],
      "metadata": {
        "id": "3oUsEqZzCMha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eev6z2nX5-im",
        "outputId": "ab424be8-b746-43e0-c991-2a75dffaf991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10,\n",
              "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('LogReg',\n",
              "                                        LogisticRegression(random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'LogReg__C': [0.6, 0.7, 0.8, 0.9],\n",
              "                         'LogReg__max_iter': [180, 200],\n",
              "                         'tfidf__analyzer': ['char'],\n",
              "                         'tfidf__max_df': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
              "                         'tfidf__min_df': array([ 5, 10]),\n",
              "                         'tfidf__ngram_range': [(1, 2)]},\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LogReg\", LogisticRegression(random_state=42))])\n",
        "\n",
        "# define parameter space to test # runtime 49min\n",
        "params = {\n",
        "     \"tfidf__analyzer\":['char'],\n",
        "     \"tfidf__ngram_range\": [(1, 2)],\n",
        "     \"tfidf__max_df\": np.arange(0.1, 1,.1),\n",
        "    \"tfidf__min_df\": np.arange(5,15,5),\n",
        "     \"LogReg__C\": [.6,.7,.8,0.9],  \n",
        "     \"LogReg__max_iter\":[180,200]    \n",
        "}\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"roc_auc\", cv= 3 ,verbose=1)\n",
        "pipe_clf.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM3d-Pdf5-ip",
        "outputId": "4d5e3d1d-0e57-44d4-b1ff-9a81e7e16e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'LogReg__C': 0.9, 'LogReg__max_iter': 180, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.7000000000000001, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "#display the best parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** Greattt, it worked as we expected and chosed the same hyperparameters using the grid search as second trial."
      ],
      "metadata": {
        "id": "PW4ueevPD8t0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFy5xw555-ir",
        "outputId": "334155b6-70ea-4215-a251-92800fb6543a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.73      0.71     31955\n",
            "           1       0.66      0.61      0.63     27468\n",
            "\n",
            "    accuracy                           0.67     59423\n",
            "   macro avg       0.67      0.67      0.67     59423\n",
            "weighted avg       0.67      0.67      0.67     59423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, Y)\n",
        "pipe_pred = pipe.predict(X)\n",
        "report = sklearn.metrics.classification_report(Y, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** it achieved 67% on whole training data."
      ],
      "metadata": {
        "id": "C7qWcHHVEKx8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spfr1GANV_CE"
      },
      "source": [
        "#**Model(5): LogReg + (analyzer='word') with (Grid Search) using (Cross Validation)** different hyperparameter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here what did we use ‚Åâ**\n",
        "\n",
        "- word analyzer with different hyperparameters that they are:\n",
        "- word analyzer \n",
        "- ngram_range(1,2): means unigrams and bigrams.\n",
        "- max_df : range between (.1:.4).\n",
        "- min_df : range between (5:15) with step 5.\n",
        " \n",
        " **We keep everything between max_df and min_df**\n",
        "- C : np.logspace(-5, 5, 10)\n",
        "- max_iter: value(200) larger than the default value(100) to help the solver to converge.\n",
        "- random_state : (set to 42) to shuffle the data.\n",
        "\n",
        "- Grid Search using Cross Validation (cv=2)."
      ],
      "metadata": {
        "id": "gwUzneeZGd5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I suggest the accuracy will enhance than the previous trials with these different hyperparameters espicially in C values.**"
      ],
      "metadata": {
        "id": "Ggb7BOAfIZ61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af226591-e7ad-4113-dfe9-44b7f42103f1",
        "id": "bxbE8Hl8V_CH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 80 candidates, totalling 160 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('LogReg',\n",
              "                                        LogisticRegression(random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'LogReg__C': array([1.00000000e-05, 1.29154967e-04, 1.66810054e-03, 2.15443469e-02,\n",
              "       2.78255940e-01, 3.59381366e+00, 4.64158883e+01, 5.99484250e+02,\n",
              "       7.74263683e+03, 1.00000000e+05]),\n",
              "                         'LogReg__max_iter': [200],\n",
              "                         'tfidf__max_df': array([0.1, 0.2, 0.3, 0.4]),\n",
              "                         'tfidf__min_df': array([ 5, 10]),\n",
              "                         'tfidf__ngram_range': [(1, 2)]},\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LogReg\", LogisticRegression(random_state=42))])\n",
        "\n",
        "# define parameter space to test # runtime 40min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2)],\n",
        "    \"tfidf__max_df\": np.arange(0.1, .4,.1),\n",
        "    \"tfidf__min_df\": np.arange(5,15,5),\n",
        "    \"LogReg__C\": np.logspace(-5, 5, 10),  \n",
        "    \"LogReg__max_iter\":[200]    \n",
        "}\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"roc_auc\", cv= 2 ,verbose=1)\n",
        "pipe_clf.fit(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F85tWFAoV_CK",
        "outputId": "d79026ea-8937-4596-8a93-a64b8f2f4793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LogReg__C': 3.593813663804626, 'LogReg__max_iter': 200, 'tfidf__max_df': 0.1, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "#display the best parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** the above cell returned the best hyperparametered with validation set using GridSearch .\n",
        "\n",
        "* max_df = 1.0, which means \"ignore terms that appear in more than 100% of the documents\". Thus, it did not ignore any terms.\n",
        "\n",
        "* min_df = 5 , which means \"ignore terms that appear in less than 5 documents\".\n"
      ],
      "metadata": {
        "id": "3wm2lIG7Jfn-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ufm3mo_V_CT",
        "outputId": "ef491ccd-4ce7-43b0-81cd-5e9bb51216d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89     31955\n",
            "           1       0.87      0.87      0.87     27468\n",
            "\n",
            "    accuracy                           0.88     59423\n",
            "   macro avg       0.88      0.88      0.88     59423\n",
            "weighted avg       0.88      0.88      0.88     59423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, Y)\n",
        "pipe_pred = pipe.predict(X)\n",
        "report = sklearn.metrics.classification_report(Y, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** The accuracy got better with increasing the value of C to become 88%."
      ],
      "metadata": {
        "id": "UIKxKoTVOpvY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-n7t2G95-tS"
      },
      "source": [
        "#**Model(6): XGBoost + (analyzer='word')  with (Random Search) using (Cross Validation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model:** XGBoost\n",
        "* XGBoost provides a highly efficient implementation of the stochastic gradient boosting algorithm and access to a suite of model hyperparameters designed to provide control over the model training process. The most important factor behind the success of XGBoost is its scalability in all scenarios.\n",
        "\n",
        "* It can be used for text classification.\n",
        "\n",
        "* XGBoost 's important hyperparameters that we used here:\n",
        "\n",
        "      1) **learning_rate** parameter can be set to control the weighting of new trees added to the model.\n",
        "\n",
        "      2) **n_estimators** is the number of trees \n",
        "\n",
        "      3) **max_depth** The maximum depth that you allow the tree to grow to. "
      ],
      "metadata": {
        "id": "KSDZF1gZQqv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here what did we use ‚Åâ**\n",
        "\n",
        "- word analyzer \n",
        "- ngram_range(1,2): means unigrams and bigrams.\n",
        "- max_df : range between (.3:.8).\n",
        "- min_df : range between (5:20) with step 5.\n",
        " \n",
        " **We keep everything between max_df and min_df**\n",
        "- learning_rate :[.001,.001,.1]\n",
        "- n_estimators: [200,300,400] \n",
        "- random_state : (set to 42) to shuffle the data.\n",
        "- max_depth: [3,6,10]\n",
        "\n",
        "- Random Search using Cross Validation( cv=2)."
      ],
      "metadata": {
        "id": "-n5jSEfZTYwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I expect that the model can give quite good accuracy as it suitable for this kind of problems.**"
      ],
      "metadata": {
        "id": "z2uaOZpAUsGg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xxBF11Q5-tT",
        "outputId": "4bfba81c-c91c-4d29-a6ba-076867012cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2,\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('XGB',\n",
              "                                              XGBClassifier(random_state=42))]),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'XGB__learning_rate': [0.001, 0.001,\n",
              "                                                               0.1],\n",
              "                                        'XGB__max_depth': [3, 6, 10],\n",
              "                                        'XGB__n_estimators': [200, 300, 400],\n",
              "                                        'tfidf__max_df': array([0.3, 0.4, 0.5, 0.6, 0.7]),\n",
              "                                        'tfidf__min_df': array([ 5, 10, 15]),\n",
              "                                        'tfidf__ngram_range': [(1, 2)]},\n",
              "                   scoring='roc_auc', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"XGB\", XGBClassifier(random_state=42))])\n",
        "\n",
        "# define parameter space to test \n",
        "params = {\n",
        "     \"tfidf__ngram_range\": [(1, 2)],\n",
        "     \"tfidf__max_df\": np.arange(0.3, 0.8,.1),\n",
        "     \"tfidf__min_df\": np.arange(5,20,5),\n",
        "     \"XGB__max_depth\": [3,6,10],  \n",
        "     \"XGB__learning_rate\":[.001,.001,.1],\n",
        "     \"XGB__n_estimators\": [200,300,400]    \n",
        "}\n",
        "pipe_clf = RandomizedSearchCV(pipe, params, n_jobs=-1, scoring=\"roc_auc\", cv= 2 ,verbose=1)\n",
        "pipe_clf.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fta3nq-R5-tW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49dcabd6-dd51-4ad7-f49d-fb454b2fb865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 5, 'tfidf__max_df': 0.4, 'XGB__n_estimators': 300, 'XGB__max_depth': 10, 'XGB__learning_rate': 0.1}\n"
          ]
        }
      ],
      "source": [
        "#display the best parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** We can see that the best result observed was a learning rate of 0.1 with 300 trees."
      ],
      "metadata": {
        "id": "vymcoUogWbZQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYOMBaJR5-tX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9853767a-f453-44e4-fabf-2386dbcdc89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85     31955\n",
            "           1       0.83      0.82      0.82     27468\n",
            "\n",
            "    accuracy                           0.84     59423\n",
            "   macro avg       0.84      0.84      0.84     59423\n",
            "weighted avg       0.84      0.84      0.84     59423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, Y)\n",
        "pipe_pred = pipe.predict(X)\n",
        "report = sklearn.metrics.classification_report(Y, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** it achieved 84% on whole training data. we observe that the model is good for this kind of problems and provide good accuracy and it would increase if we used grid search instead of random search."
      ],
      "metadata": {
        "id": "m89AXXWpWgAV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9xlQzqaTdGC"
      },
      "source": [
        "#**Model(7): RF + (analyzer='word') with (Grid Search) using (Cross Validation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will use Random forest model with the different cleaning function on input and chech the change in accuracy and i expect to increase"
      ],
      "metadata": {
        "id": "fF7beYSmXfdw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M2a2GQ8TdGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9cba43-75ce-484e-b0a4-0971fb635c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('RF',\n",
              "                                        RandomForestClassifier(max_depth=10))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'RF__n_estimators': [300, 350],\n",
              "                         'tfidf__max_df': array([0.3, 0.4]),\n",
              "                         'tfidf__min_df': array([ 5, 10]),\n",
              "                         'tfidf__ngram_range': [(1, 2)]},\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"RF\", RandomForestClassifier( max_depth=10))])\n",
        "\n",
        "# define parameter space to test # runtime 40min\n",
        "params = {\n",
        "     \"tfidf__ngram_range\": [(1, 2)],\n",
        "     \"tfidf__max_df\": np.arange(0.3, 0.5,.1),\n",
        "     \"tfidf__min_df\": np.arange(5,15,5),\n",
        "     \"RF__n_estimators\":[300 ,350]  \n",
        "}\n",
        "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"roc_auc\", cv= 3 ,verbose=1)\n",
        "pipe_clf.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RicZEOnOTdGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f54fab-8be7-4e0f-b13e-79225132a6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RF__n_estimators': 350, 'tfidf__max_df': 0.3, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "#display the best parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** we can see that the best number of trees used is 350 tree with max_df equal to .3 and min_df equal to 50%."
      ],
      "metadata": {
        "id": "wnE8pQF1X1yC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5Pd3EePTdGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2aa0a5-e7ab-4fc2-cf52-56b05a7db042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.99      0.72     31955\n",
            "           1       0.91      0.13      0.23     27468\n",
            "\n",
            "    accuracy                           0.59     59423\n",
            "   macro avg       0.74      0.56      0.48     59423\n",
            "weighted avg       0.73      0.59      0.50     59423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, Y)\n",
        "pipe_pred = pipe.predict(X)\n",
        "report = sklearn.metrics.classification_report(Y, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** it gave me test accuracy on kaggle equal to 87% which is the best accuracy achieved so random forest model is the best model out of the three models we tried."
      ],
      "metadata": {
        "id": "7i6DmFRbYLz1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGAb5R7tl0yN"
      },
      "source": [
        "#**Submission file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCBBQ01KkknG"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['id'] = df2['id']\n",
        "submission['label'] = pipe.predict_proba(df2['clean_text'])[:, 1]\n",
        "\n",
        "submission.to_csv('logreg.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RipVl2OQsChu",
        "BGBooHpxqnBk",
        "hgX7zTcFfy8o",
        "vSYddjXEKP6f",
        "Cx7BGt6XKgzh",
        "QHvFrT0xb_jX",
        "zwJntJEucXfB",
        "x2IVbwa4ZkYY",
        "t9RfnC-cZv5V",
        "0LO2ITy_dCQz",
        "jnbRnWNuqJGc",
        "d5Zlo-61t4Je",
        "VZk5jJ6SkGYK",
        "xtB_TY_5xukN",
        "Cwne6Cymx1fp",
        "oWIFGhQWXxNA",
        "-qOGjBxM5-Pf",
        "cN_O6d8q5-ZB",
        "Ps3lB6Zy5-ii",
        "spfr1GANV_CE",
        "J-n7t2G95-tS",
        "c9xlQzqaTdGC"
      ],
      "name": "Fake Reddit Prediction",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}